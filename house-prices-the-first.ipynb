{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# House prices: The First \n\nFork from:  \n* [House prices: Easy mode (top 12%)](https://www.kaggle.com/code/matthieugouel/house-prices-easy-mode-top-12/notebook)\n\nSources that helped me a lot:\n* [Stacked Ensemble Models (Top 3% on Leaderboard)](https://www.kaggle.com/code/alexturkmen/preprocessing-modeling-with-stacking-top-5#2---Preprocessing)\n* [Preprocessing & Modeling with Stacking -->Top 5%](https://www.kaggle.com/code/limyenwee/stacked-ensemble-models-top-3-on-leaderboard)\n\n* **目标**：  \n1. 参照现有逻辑，简单的生成初版模型，最好达到TOP3%;  \n2. 采用shap方法，对其归因分析,聚类。","metadata":{"editable":false}},{"cell_type":"markdown","source":"## Part1:Initialization\n\nIn this section we import the dataset and the required packages.","metadata":{"editable":false}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import RobustScaler, OrdinalEncoder\nfrom sklearn.metrics import mean_squared_log_error, r2_score,accuracy_score\n\nfrom xgboost import XGBRegressor\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom shap import Explainer\n\n# Dataset directory\nbase_path = Path(\"../input/house-prices-advanced-regression-techniques\")","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(base_path / \"train.csv\")\ndf_test = pd.read_csv(base_path / \"test.csv\")\n\nX = df_train.drop(columns=['SalePrice', 'Id'])\ny = df_train['SalePrice']\n\ncategoric_feats = X.dtypes[X.dtypes == \"object\"].index\nX[categoric_feats]=X[categoric_feats].astype(\"category\")\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=8888)\n\nyy_test=df_test.drop(columns=['Id'])\nyy_test[categoric_feats]=yy_test[categoric_feats].astype(\"category\")","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Part2:MVP Model --minimum viable product  model  \n**Modeling**  \nWe only use LightGBM ensemble regressor, and not perform stacking/blending of different models, for simplicity.\nThe hyper parameter tuning has been applied and then commented.\n1. 探索数据\n2. 采用xgboost直接建模，生成结果，获得基础得分","metadata":{"editable":false}},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(16,4))\ndf_train[\"SalePrice\"].plot.hist(bins=50,ax=ax)\n#sns.displot(df_train[\"SalePrice\"])\nprint(\"skew=\",df_train[\"SalePrice\"].skew(),\"kurt=\",df_train[\"SalePrice\"].kurt())\nprint(df_train[\"SalePrice\"].describe())","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LightGBM 初步建模\nmodel = lgb.LGBMRegressor(n_estimators=1500, learning_rate=0.02, max_depth=6, subsample=0.7)\nmodel.fit(X_train, y_train, categorical_feature=categoric_feats.to_list())\n\n# 对模型的预测结果进行评判\ny_pred=model.predict(X_test)\n\nprint(\"Mean Absolute Error : \" + str(mean_squared_log_error(model.predict(X_test), y_test)))\nprint(\"r2_score : \" + str(r2_score(y_pred, y_test)))\n\nyy_pred=model.predict(yy_test)\nyy_pred.tofile(\"../working/house-prices-predV1.csv\")","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax=plt.subplots(figsize=(16,8))\nlgb.plot_importance(model, max_num_features=30,ax=ax)\nplt.title(\"Featurertances\",fontsize=15)\n# plt.ylabel(fontsize=15)\nf.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 用shap方法进行模型解释","metadata":{"editable":false}},{"cell_type":"code","source":"","metadata":{"editable":false},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 模型自动调参","metadata":{"editable":false}},{"cell_type":"code","source":"callbacks = [lgb.log_evaluation(period=100), lgb.early_stopping(stopping_rounds=30)]\ncv_results = lightgbm.cv(\n                    params,\n                    lgb_train,\n                    seed=1,\n                    nfold=5,\n                    metrics='auc',\n                    callbacks=callbacks\n                    )\n\n#LightGBM 初步建模\n\n\nmodel2 = lgb.LGBMRegressor(n_estimators=1500, learning_rate=0.02, max_depth=6, subsample=0.7)\nmodel2.fit(X_train, y_train, categorical_feature=categoric_feats.to_list(),callbacks=callbacks)\n\n# 对模型的预测结果进行评判\ny_pred=model.predict(X_test)\n\nprint(\"Mean Absolute Error : \" + str(mean_squared_log_error(model.predict(X_test), y_test)))\nprint(\"r2_score : \" + str(r2_score(y_pred, y_test)))\n","metadata":{"_kg_hide-output":true,"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n**Exploratory Data Analysis (EDA)**  \nwe model our regressor and evaluate it.  * There is numerical and categorical features  \n* There are missing values\n* The numerical values are not scaled\n* The target values (SalePrice) is skewed  \n\n\n\nIn this section, we perform some basic feature engineering: \n\n* Split features into numerical and categorical data\n* Fill missing numerical values with mean\n* Fill missing categorical vues with a \"Missing\" category\n* Scale numerical features \n* Encode categorical features into numbers\n* Apply a log transformation to target values to mitigate the skewness","metadata":{"editable":false}},{"cell_type":"code","source":"# Visualize missing values\ntotal = X.isnull().sum().sort_values(ascending=False)\npercent = (X.isnull().sum()/X.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20).T","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(16,4))\nplt.xticks(rotation='90')\nmissing_data['Percent'][:20].plot.bar(ax=ax)\n# sns.barplot(x=missing_data.index, y=missing_data['Percent',:20])\nplt.title('Percent missing data by feature', fontsize=15)\nplt.xlabel('Features', fontsize=15)\nplt.ylabel('Percent of missing values', fontsize=15)\nplt.show()","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get numerical and categorical features\nnumeric_feats = X.dtypes[X.dtypes != \"object\"].index\ncategoric_feats = X.dtypes[X.dtypes == \"object\"].index\n\n# Get features with missing values\nna_numeric_feats = [k for k, v in X[numeric_feats].isnull().sum().to_dict().items() if v > 0]\nna_categoric_feats = [k for k, v in X[categoric_feats].isnull().sum().to_dict().items() if v > 0]\n\n# Clean numerical features with missing values\nimp = SimpleImputer(strategy=\"mean\")\nX_train[na_numeric_feats] = imp.fit_transform(X_train[na_numeric_feats])\nX_val[na_numeric_feats] = imp.transform(X_val[na_numeric_feats])\n\n# Clean categorical features with missing values\nfor feat in na_categoric_feats:\n    X_train[feat].fillna(\"Missing\", inplace=True)\n    X_val[feat].fillna(\"Missing\", inplace=True)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scale numerical features\nfor feat in numeric_feats:\n    scaler = RobustScaler()\n    X_train[feat] = scaler.fit_transform(X_train[feat].values.reshape(-1, 1))\n    X_val[feat] = scaler.transform(X_val[feat].values.reshape(-1, 1))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encode categorical features\nfor feat in categoric_feats:\n    encoder = OrdinalEncoder()\n    X_train[feat] = encoder.fit_transform(X_train[feat].values.reshape(-1, 1))\n    X_val[feat] = encoder.fit_transform(X_val[feat].values.reshape(-1, 1))","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Log-transformation of skewed target variable\ny_train = np.log1p(y_train)\ny_val = np.log1p(y_val)","metadata":{"editable":false,"trusted":true},"execution_count":null,"outputs":[]}]}